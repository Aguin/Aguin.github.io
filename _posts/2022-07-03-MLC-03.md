---
title: "[MLC-机器学习编译]03 张量程序实践"
date: 2022-07-03
categories:
  - Notes
tags:
  - MLC
classes: wide
---

{% include video id="BV1c94y1d7rW" provider="bilibili" danmaku="1" %}

[official notes (English)](https://mlc.ai/chapter_tensor_program/case_study.html){: .btn .btn--primary}

## 笔记
- 首先对上节课一些没有详细介绍的概念给出解释:
  - `block`: 用于计算单元.
  - `axis`:
    - `[block_axis] = T.axis.[axis_type]([axis_range], [mapped_value])`
    - 为什么要指定axis? A: 提供了额外信息, 可能对程序优化是有帮助的, 当然也可能是冗余的或者能被程序分析得到.
    - 指定维度是期望block内部是自洽的, 课程中提到如果axis维度和循环维度不一致会报错, 和我实测有些出入, 等待助教在[discussion](https://github.com/mlc-ai/mlc-zh/discussions/24)的解答.
    - `axis.spatial`: 输入输出中都包含的axis, 互相独立(可调换顺序).
    - `axis.reduce`: 只在输入中包含, 在输出中被reduce掉的axis.
    - Sugars: `vi, vj, vk = T.axis.remap("SSR", [i, j, k])`
  - 属性声明: `global_symbol`是函数名, `tir.noalias`表示buffer没有重名.
- 以low-level`numpy`实现矩阵乘为例, 演示循环展开和算子合并, 对加速原理进行了一些解释:
  - 循环展开: L1 Cache会缓存周围一段, 连续访问会比较快.
  - 合并处用了两个新函数:
    - `reverse_compute_at`: 给定`block`和`loop`, 会把指定`block`移动至`loop`下.
    - `decompose_reduction`: 把指定的`block`拆分为`init_block`和`update_block`, `init_block`移动至指定的`loop`前.
- 补充介绍了上节课最后剩的张量表达式(TE).
